{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the landmark string and return a list of floats\n",
    "def parse_landmark_string(landmark_str):\n",
    "    # Split the string by commas, then parse each key-value pair\n",
    "    landmark_values = []\n",
    "    for item in landmark_str.split(','):\n",
    "        try:\n",
    "            # Split by ':' and take the second element, then strip spaces and convert to float\n",
    "            value = float(item.split(':')[1].strip())\n",
    "            landmark_values.append(value)\n",
    "        except ValueError:\n",
    "            # Handle cases where the conversion fails (e.g., empty strings or malformed data)\n",
    "            continue\n",
    "    return landmark_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the parsing function to each row in the 'poseLandmarks' column\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Ensure to handle NaN values first as shown previously\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposeLandmarks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposeLandmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_landmark_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Convert the list of lists into a numpy array\u001b[39;00m\n\u001b[0;32m     31\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposeLandmarks\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32mc:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\pandas\\core\\series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4780\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mparse_landmark_string\u001b[1;34m(landmark_str)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m landmark_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Split by ':' and take the second element, then strip spaces and convert to float\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m      9\u001b[0m         landmark_values\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Handle cases where the conversion fails (e.g., empty strings or malformed data)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('imagePoses.csv')\n",
    "\n",
    "# Process base64 images if necessary (this step is omitted as it depends on further processing needs)\n",
    "\n",
    "# # Extract pose landmarks and convert them from lists stored as text to numpy arrays\n",
    "# import ast  # Import Abstract Syntax Trees module\n",
    "# # Drop rows where 'poseLandmarks' is NaN\n",
    "# df = df.dropna(subset=['poseLandmarks'])\n",
    "\n",
    "# df['poseLandmarks'] = df['poseLandmarks'].apply(ast.literal_eval)  # Convert stringified lists to actual lists\n",
    "# X = np.array(df['poseLandmarks'].tolist())  # Convert lists to a numpy array\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Apply the parsing function to each row in the 'poseLandmarks' column\n",
    "# Ensure to handle NaN values first as shown previously\n",
    "df['poseLandmarks'] = df['poseLandmarks'].fillna('[]').apply(parse_landmark_string)\n",
    "\n",
    "# Convert the list of lists into a numpy array\n",
    "X = np.array(df['poseLandmarks'].tolist())\n",
    "\n",
    "# Now, you can proceed with scaling\n",
    "X_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1))\n",
    "\n",
    "\n",
    "\n",
    "# Normalize landmarks data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1))  # Reshape for StandardScaler and then transform\n",
    "X_scaled = X_scaled.reshape(X.shape)  # Reshape back to original shape\n",
    "\n",
    "# Encode the labels (exercise names) to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df['exercise'])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input data for LSTM. LSTM expects data in the shape of [samples, time steps, features].\n",
    "# Adjust based on the actual structure of your landmarks data. Assuming each landmark frame is a single time step:\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], -1))  # Adjusted reshape\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], -1))  # Adjusted reshape\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # The output layer with a softmax activation\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.3)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2112, 1, 132) (2112, 9) (529, 1, 132) (529, 9)\n",
      "Epoch 1/120\n",
      "24/24 [==============================] - 6s 55ms/step - loss: 2.1794 - accuracy: 0.1725 - val_loss: 2.1393 - val_accuracy: 0.3533\n",
      "Epoch 2/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.1076 - accuracy: 0.2950 - val_loss: 2.0588 - val_accuracy: 0.3770\n",
      "Epoch 3/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.0168 - accuracy: 0.3640 - val_loss: 1.9436 - val_accuracy: 0.4101\n",
      "Epoch 4/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.8940 - accuracy: 0.3985 - val_loss: 1.8004 - val_accuracy: 0.4148\n",
      "Epoch 5/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.7609 - accuracy: 0.4222 - val_loss: 1.6656 - val_accuracy: 0.4353\n",
      "Epoch 6/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.6318 - accuracy: 0.4567 - val_loss: 1.5457 - val_accuracy: 0.4543\n",
      "Epoch 7/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5379 - accuracy: 0.4547 - val_loss: 1.4460 - val_accuracy: 0.4748\n",
      "Epoch 8/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4654 - accuracy: 0.4858 - val_loss: 1.3631 - val_accuracy: 0.5016\n",
      "Epoch 9/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.3790 - accuracy: 0.5047 - val_loss: 1.2937 - val_accuracy: 0.5174\n",
      "Epoch 10/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3202 - accuracy: 0.5345 - val_loss: 1.2237 - val_accuracy: 0.5505\n",
      "Epoch 11/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.2511 - accuracy: 0.5467 - val_loss: 1.1646 - val_accuracy: 0.5804\n",
      "Epoch 12/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.1864 - accuracy: 0.5744 - val_loss: 1.1170 - val_accuracy: 0.5899\n",
      "Epoch 13/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.5981 - val_loss: 1.0743 - val_accuracy: 0.6183\n",
      "Epoch 14/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.1024 - accuracy: 0.6049 - val_loss: 1.0377 - val_accuracy: 0.6183\n",
      "Epoch 15/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.0679 - accuracy: 0.6096 - val_loss: 1.0104 - val_accuracy: 0.6120\n",
      "Epoch 16/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0295 - accuracy: 0.6198 - val_loss: 0.9658 - val_accuracy: 0.6483\n",
      "Epoch 17/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.0382 - accuracy: 0.6279 - val_loss: 0.9323 - val_accuracy: 0.6625\n",
      "Epoch 18/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.9928 - accuracy: 0.6387 - val_loss: 0.9184 - val_accuracy: 0.6530\n",
      "Epoch 19/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.9849 - accuracy: 0.6380 - val_loss: 0.8895 - val_accuracy: 0.6782\n",
      "Epoch 20/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.9635 - accuracy: 0.6543 - val_loss: 0.8713 - val_accuracy: 0.6735\n",
      "Epoch 21/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.9449 - accuracy: 0.6746 - val_loss: 0.8542 - val_accuracy: 0.6767\n",
      "Epoch 22/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.9155 - accuracy: 0.6705 - val_loss: 0.8368 - val_accuracy: 0.6924\n",
      "Epoch 23/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.9113 - accuracy: 0.6651 - val_loss: 0.8188 - val_accuracy: 0.7003\n",
      "Epoch 24/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.8833 - accuracy: 0.6685 - val_loss: 0.8114 - val_accuracy: 0.6972\n",
      "Epoch 25/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.8576 - accuracy: 0.6847 - val_loss: 0.7988 - val_accuracy: 0.6956\n",
      "Epoch 26/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.8515 - accuracy: 0.6854 - val_loss: 0.7828 - val_accuracy: 0.7003\n",
      "Epoch 27/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.8408 - accuracy: 0.6935 - val_loss: 0.7690 - val_accuracy: 0.7098\n",
      "Epoch 28/120\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.8197 - accuracy: 0.6942 - val_loss: 0.7661 - val_accuracy: 0.7003\n",
      "Epoch 29/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.8170 - accuracy: 0.6908 - val_loss: 0.7633 - val_accuracy: 0.7082\n",
      "Epoch 30/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.7954 - accuracy: 0.7009 - val_loss: 0.7467 - val_accuracy: 0.7192\n",
      "Epoch 31/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.7917 - accuracy: 0.7070 - val_loss: 0.7306 - val_accuracy: 0.7287\n",
      "Epoch 32/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.7736 - accuracy: 0.7097 - val_loss: 0.7317 - val_accuracy: 0.7161\n",
      "Epoch 33/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.7375 - accuracy: 0.7341 - val_loss: 0.7205 - val_accuracy: 0.7240\n",
      "Epoch 34/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 0.7355 - val_loss: 0.7255 - val_accuracy: 0.7256\n",
      "Epoch 35/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.7244 - accuracy: 0.7449 - val_loss: 0.7226 - val_accuracy: 0.7271\n",
      "Epoch 36/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.7551 - val_loss: 0.7050 - val_accuracy: 0.7366\n",
      "Epoch 37/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.7544 - val_loss: 0.6908 - val_accuracy: 0.7382\n",
      "Epoch 38/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.7247 - accuracy: 0.7246 - val_loss: 0.7070 - val_accuracy: 0.7240\n",
      "Epoch 39/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.7203 - accuracy: 0.7172 - val_loss: 0.6986 - val_accuracy: 0.7350\n",
      "Epoch 40/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.7470 - val_loss: 0.6960 - val_accuracy: 0.7287\n",
      "Epoch 41/120\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6795 - accuracy: 0.7591 - val_loss: 0.6838 - val_accuracy: 0.7382\n",
      "Epoch 42/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.7497 - val_loss: 0.6816 - val_accuracy: 0.7334\n",
      "Epoch 43/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.7639 - val_loss: 0.6966 - val_accuracy: 0.7350\n",
      "Epoch 44/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6621 - accuracy: 0.7409 - val_loss: 0.6773 - val_accuracy: 0.7397\n",
      "Epoch 45/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6483 - accuracy: 0.7530 - val_loss: 0.6728 - val_accuracy: 0.7461\n",
      "Epoch 46/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7733 - val_loss: 0.6703 - val_accuracy: 0.7524\n",
      "Epoch 47/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.7544 - val_loss: 0.6669 - val_accuracy: 0.7461\n",
      "Epoch 48/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.7510 - val_loss: 0.6675 - val_accuracy: 0.7524\n",
      "Epoch 49/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.7774 - val_loss: 0.6639 - val_accuracy: 0.7555\n",
      "Epoch 50/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6228 - accuracy: 0.7700 - val_loss: 0.6718 - val_accuracy: 0.7397\n",
      "Epoch 51/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.7760 - val_loss: 0.6659 - val_accuracy: 0.7508\n",
      "Epoch 52/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.7578 - val_loss: 0.6567 - val_accuracy: 0.7413\n",
      "Epoch 53/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.7733 - val_loss: 0.6660 - val_accuracy: 0.7445\n",
      "Epoch 54/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.7788 - val_loss: 0.6650 - val_accuracy: 0.7492\n",
      "Epoch 55/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5943 - accuracy: 0.7828 - val_loss: 0.6502 - val_accuracy: 0.7413\n",
      "Epoch 56/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6297 - accuracy: 0.7794 - val_loss: 0.6527 - val_accuracy: 0.7461\n",
      "Epoch 57/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.7909 - val_loss: 0.6375 - val_accuracy: 0.7476\n",
      "Epoch 58/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.7794 - val_loss: 0.6446 - val_accuracy: 0.7603\n",
      "Epoch 59/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.7794 - val_loss: 0.6503 - val_accuracy: 0.7555\n",
      "Epoch 60/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5783 - accuracy: 0.7862 - val_loss: 0.6500 - val_accuracy: 0.7524\n",
      "Epoch 61/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.7774 - val_loss: 0.6395 - val_accuracy: 0.7587\n",
      "Epoch 62/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7923 - val_loss: 0.6455 - val_accuracy: 0.7571\n",
      "Epoch 63/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7957 - val_loss: 0.6415 - val_accuracy: 0.7555\n",
      "Epoch 64/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.8011 - val_loss: 0.6511 - val_accuracy: 0.7587\n",
      "Epoch 65/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.8133 - val_loss: 0.6450 - val_accuracy: 0.7539\n",
      "Epoch 66/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.8153 - val_loss: 0.6495 - val_accuracy: 0.7603\n",
      "Epoch 67/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.8038 - val_loss: 0.6490 - val_accuracy: 0.7555\n",
      "Epoch 68/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7997 - val_loss: 0.6326 - val_accuracy: 0.7571\n",
      "Epoch 69/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.8099 - val_loss: 0.6486 - val_accuracy: 0.7492\n",
      "Epoch 70/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8065 - val_loss: 0.6468 - val_accuracy: 0.7524\n",
      "Epoch 71/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.8024 - val_loss: 0.6409 - val_accuracy: 0.7587\n",
      "Epoch 72/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7984 - val_loss: 0.6295 - val_accuracy: 0.7603\n",
      "Epoch 73/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7984 - val_loss: 0.6416 - val_accuracy: 0.7744\n",
      "Epoch 74/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8133 - val_loss: 0.6260 - val_accuracy: 0.7729\n",
      "Epoch 75/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.8241 - val_loss: 0.6194 - val_accuracy: 0.7603\n",
      "Epoch 76/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.8221 - val_loss: 0.6253 - val_accuracy: 0.7650\n",
      "Epoch 77/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7991 - val_loss: 0.6497 - val_accuracy: 0.7539\n",
      "Epoch 78/120\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.8139 - val_loss: 0.6315 - val_accuracy: 0.7650\n",
      "Epoch 79/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.8112 - val_loss: 0.6282 - val_accuracy: 0.7666\n",
      "Epoch 80/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.8146 - val_loss: 0.6090 - val_accuracy: 0.7666\n",
      "Epoch 81/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8166 - val_loss: 0.6205 - val_accuracy: 0.7634\n",
      "Epoch 82/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.8092 - val_loss: 0.6145 - val_accuracy: 0.7681\n",
      "Epoch 83/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.8085 - val_loss: 0.6208 - val_accuracy: 0.7666\n",
      "Epoch 84/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.8383 - val_loss: 0.6130 - val_accuracy: 0.7666\n",
      "Epoch 85/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8315 - val_loss: 0.6108 - val_accuracy: 0.7650\n",
      "Epoch 86/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.8396 - val_loss: 0.6094 - val_accuracy: 0.7666\n",
      "Epoch 87/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.8302 - val_loss: 0.6113 - val_accuracy: 0.7697\n",
      "Epoch 88/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.8281 - val_loss: 0.6061 - val_accuracy: 0.7634\n",
      "Epoch 89/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.8315 - val_loss: 0.6196 - val_accuracy: 0.7634\n",
      "Epoch 90/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.8200 - val_loss: 0.6185 - val_accuracy: 0.7697\n",
      "Epoch 91/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8376 - val_loss: 0.6106 - val_accuracy: 0.7776\n",
      "Epoch 92/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.8329 - val_loss: 0.6134 - val_accuracy: 0.7744\n",
      "Epoch 93/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.8383 - val_loss: 0.6185 - val_accuracy: 0.7760\n",
      "Epoch 94/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.8187 - val_loss: 0.6006 - val_accuracy: 0.7855\n",
      "Epoch 95/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.8329 - val_loss: 0.6042 - val_accuracy: 0.7760\n",
      "Epoch 96/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8349 - val_loss: 0.6012 - val_accuracy: 0.7760\n",
      "Epoch 97/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8505 - val_loss: 0.6032 - val_accuracy: 0.7839\n",
      "Epoch 98/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8410 - val_loss: 0.6170 - val_accuracy: 0.7776\n",
      "Epoch 99/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8315 - val_loss: 0.6156 - val_accuracy: 0.7618\n",
      "Epoch 100/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8383 - val_loss: 0.6339 - val_accuracy: 0.7697\n",
      "Epoch 101/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.8295 - val_loss: 0.6231 - val_accuracy: 0.7808\n",
      "Epoch 102/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8599 - val_loss: 0.6231 - val_accuracy: 0.7776\n",
      "Epoch 103/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8390 - val_loss: 0.6264 - val_accuracy: 0.7760\n",
      "Epoch 104/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.8457 - val_loss: 0.6272 - val_accuracy: 0.7760\n",
      "Epoch 105/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8471 - val_loss: 0.6153 - val_accuracy: 0.7729\n",
      "Epoch 106/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8396 - val_loss: 0.6247 - val_accuracy: 0.7650\n",
      "Epoch 107/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.8336 - val_loss: 0.6152 - val_accuracy: 0.7713\n",
      "Epoch 108/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8491 - val_loss: 0.6187 - val_accuracy: 0.7760\n",
      "Epoch 109/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8356 - val_loss: 0.6200 - val_accuracy: 0.7729\n",
      "Epoch 110/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8593 - val_loss: 0.5923 - val_accuracy: 0.7839\n",
      "Epoch 111/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8457 - val_loss: 0.6010 - val_accuracy: 0.7839\n",
      "Epoch 112/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8464 - val_loss: 0.6335 - val_accuracy: 0.7792\n",
      "Epoch 113/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8356 - val_loss: 0.6077 - val_accuracy: 0.7871\n",
      "Epoch 114/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8539 - val_loss: 0.6038 - val_accuracy: 0.7886\n",
      "Epoch 115/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8545 - val_loss: 0.6086 - val_accuracy: 0.7776\n",
      "Epoch 116/120\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3992 - accuracy: 0.8559 - val_loss: 0.6123 - val_accuracy: 0.7776\n",
      "Epoch 117/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8512 - val_loss: 0.6215 - val_accuracy: 0.7760\n",
      "Epoch 118/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8532 - val_loss: 0.6273 - val_accuracy: 0.7792\n",
      "Epoch 119/120\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8471 - val_loss: 0.6351 - val_accuracy: 0.7808\n",
      "Epoch 120/120\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8572 - val_loss: 0.6323 - val_accuracy: 0.7855\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.7410\n",
      "Test accuracy: 74.10%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('imagePoses.csv')  # Update the path as needed\n",
    "\n",
    "#drop the row if the column landmark is emptpy\n",
    "df = df.dropna(subset=['poseLandmarks'])\n",
    "\n",
    "# Define a function to extract numerical values from the poseLandmarks string\n",
    "def extract_landmarks(landmark_str):\n",
    "    # Initialize an empty list to hold the extracted numerical values\n",
    "    landmarks = []\n",
    "    # Split the string into parts based on commas\n",
    "    parts = landmark_str.split(',')\n",
    "    # Iterate over each part and extract the numerical value\n",
    "    for part in parts:\n",
    "        try:\n",
    "            # Extract the numerical value after the colon and convert it to float\n",
    "            value = float(part.split(':')[1])\n",
    "            landmarks.append(value)\n",
    "        except (ValueError, IndexError):\n",
    "            # If conversion fails or the split doesn't work as expected, skip this part\n",
    "            continue\n",
    "    return landmarks\n",
    "\n",
    "# Apply the function to each row in the 'poseLandmarks' column\n",
    "df['poseLandmarks'] = df['poseLandmarks'].apply(lambda x: extract_landmarks(x) if pd.notnull(x) else [])\n",
    "\n",
    "# Convert the list of lists into a numpy array for the features\n",
    "X = np.array(df['poseLandmarks'].tolist())\n",
    "\n",
    "# Flatten X for StandardScaler\n",
    "X_flattened = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df['excercise'])\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_flattened)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    LSTM(32),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=120, batch_size=64, validation_split=0.3)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler2.save']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model.save('exercise_recognition_model2.keras')\n",
    "joblib.dump(label_encoder, 'label_encoder2.joblib')\n",
    "joblib.dump(scaler, 'scaler2.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
