{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('landmarks_and_labels.csv')\n",
    "\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9   \\\n",
       "0     True  False  False  False  False  False  False  False  False  False   \n",
       "1    False   True  False  False  False  False  False  False  False  False   \n",
       "2     True  False  False  False  False  False  False  False  False  False   \n",
       "3    False   True  False  False  False  False  False  False  False  False   \n",
       "4     True  False  False  False  False  False  False  False  False  False   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "428  False  False  False  False  False  False  False  False  False  False   \n",
       "429  False  False  False  False  False  False  False  False  False  False   \n",
       "430  False  False  False  False  False  False  False  False  False  False   \n",
       "431  False  False  False  False  False  False  False  False  False  False   \n",
       "432  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "        10     11     12     13  \n",
       "0    False  False  False  False  \n",
       "1    False  False  False  False  \n",
       "2    False  False  False  False  \n",
       "3    False  False  False  False  \n",
       "4    False  False  False  False  \n",
       "..     ...    ...    ...    ...  \n",
       "428  False  False  False   True  \n",
       "429  False  False   True  False  \n",
       "430  False  False  False   True  \n",
       "431  False  False   True  False  \n",
       "432  False  False  False   True  \n",
       "\n",
       "[433 rows x 14 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split label column\n",
    "labels = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = pd.get_dummies(labels)\n",
    "\n",
    "# Split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 128 neurons, dropout 0.2, l1 1e-05, l2 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 128 neurons, dropout 0.2, l1 1e-05, l2 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 128 neurons, dropout 0.2, l1 1e-06, l2 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 128 neurons, dropout 0.2, l1 1e-06, l2 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 128 neurons, dropout 0.3, l1 1e-05, l2 0.0001\n",
      "Training model with 128 neurons, dropout 0.3, l1 1e-05, l2 0.001\n",
      "Training model with 128 neurons, dropout 0.3, l1 1e-06, l2 0.0001\n",
      "Training model with 128 neurons, dropout 0.3, l1 1e-06, l2 0.001\n",
      "Training model with 128 neurons, dropout 0.4, l1 1e-05, l2 0.0001\n",
      "Training model with 128 neurons, dropout 0.4, l1 1e-05, l2 0.001\n",
      "Training model with 128 neurons, dropout 0.4, l1 1e-06, l2 0.0001\n",
      "Training model with 128 neurons, dropout 0.4, l1 1e-06, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.2, l1 1e-05, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.2, l1 1e-05, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.2, l1 1e-06, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.2, l1 1e-06, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.3, l1 1e-05, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.3, l1 1e-05, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.3, l1 1e-06, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.3, l1 1e-06, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.4, l1 1e-05, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.4, l1 1e-05, l2 0.001\n",
      "Training model with 256 neurons, dropout 0.4, l1 1e-06, l2 0.0001\n",
      "Training model with 256 neurons, dropout 0.4, l1 1e-06, l2 0.001\n",
      "Training model with 512 neurons, dropout 0.2, l1 1e-05, l2 0.0001\n",
      "Training model with 512 neurons, dropout 0.2, l1 1e-05, l2 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 512 neurons, dropout 0.2, l1 1e-06, l2 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaaab\\.conda\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 512 neurons, dropout 0.2, l1 1e-06, l2 0.001\n",
      "Training model with 512 neurons, dropout 0.3, l1 1e-05, l2 0.0001\n",
      "Training model with 512 neurons, dropout 0.3, l1 1e-05, l2 0.001\n",
      "Training model with 512 neurons, dropout 0.3, l1 1e-06, l2 0.0001\n",
      "Training model with 512 neurons, dropout 0.3, l1 1e-06, l2 0.001\n",
      "Training model with 512 neurons, dropout 0.4, l1 1e-05, l2 0.0001\n",
      "Training model with 512 neurons, dropout 0.4, l1 1e-05, l2 0.001\n",
      "Training model with 512 neurons, dropout 0.4, l1 1e-06, l2 0.0001\n",
      "Training model with 512 neurons, dropout 0.4, l1 1e-06, l2 0.001\n",
      "Best configuration: Neurons: 512, Dropout Rate: 0.2, l1: 1e-06, l2: 0.0001 with Validation Accuracy: 0.8857142925262451\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Define your grid search parameters\n",
    "neurons_list = [128, 256, 512]  # Example: varying number of neurons\n",
    "dropout_list = [0.2, 0.3, 0.4]  # Example: varying dropout rates\n",
    "l1_list = [1e-5, 1e-6]\n",
    "l2_list = [1e-4, 1e-3]\n",
    "\n",
    "# Placeholder for best configuration\n",
    "best_acc = -np.inf\n",
    "best_config = None\n",
    "\n",
    "for neurons in neurons_list:\n",
    "    for dropout_rate in dropout_list:\n",
    "        for l1 in l1_list:\n",
    "            for l2 in l2_list:\n",
    "                print(\n",
    "                    f\"Training model with {neurons} neurons, dropout {dropout_rate}, l1 {l1}, l2 {l2}\"\n",
    "                )\n",
    "\n",
    "                # Define L1 and L2 regularizers dynamically\n",
    "                regularizers = l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "                # Rebuild the model with the new parameters\n",
    "                model = Sequential(\n",
    "                    [\n",
    "                        Dense(\n",
    "                            neurons,\n",
    "                            input_shape=(X_train.shape[1],),\n",
    "                            kernel_regularizer=regularizers,\n",
    "                        ),\n",
    "                        BatchNormalization(),\n",
    "                        Activation(\"swish\"),\n",
    "                        Dropout(dropout_rate),\n",
    "                        Dense(\n",
    "                            int(neurons / 2), kernel_regularizer=regularizers\n",
    "                        ),  # Dynamically reduce neuron count for the second layer\n",
    "                        BatchNormalization(),\n",
    "                        Activation(\"swish\"),\n",
    "                        Dropout(dropout_rate),\n",
    "                        Dense(y_train.shape[1], activation=\"softmax\"),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                optimizer = Adam(learning_rate=0.001)\n",
    "                model.compile(\n",
    "                    optimizer=optimizer,\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=[\"accuracy\"],\n",
    "                )\n",
    "\n",
    "                # Fit the model (consider using a smaller number of epochs for grid search)\n",
    "                history = model.fit(\n",
    "                    X_train, y_train, epochs=50, validation_split=0.1, verbose=0\n",
    "                )  # Use verbose=0 for less output\n",
    "\n",
    "                # Evaluate the model\n",
    "                val_acc = np.max(\n",
    "                    history.history[\"val_accuracy\"]\n",
    "                )  # Get the best validation accuracy\n",
    "\n",
    "                # Update best configuration if current model is better\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_config = (neurons, dropout_rate, l1, l2)\n",
    "                    # Consider saving the model here if you want to keep the best model\n",
    "                    model.save(\"best_model_grid_search.h5\")\n",
    "\n",
    "print(\n",
    "    f\"Best configuration: Neurons: {best_config[0]}, Dropout Rate: {best_config[1]}, l1: {best_config[2]}, l2: {best_config[3]} with Validation Accuracy: {best_acc}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
