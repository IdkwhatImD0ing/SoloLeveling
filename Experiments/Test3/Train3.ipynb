{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the csv as a df\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('data/landmarks.csv')\n",
    "df2 = pd.read_csv('data/labels.csv')\n",
    "\n",
    "df = pd.merge(df2, df1, on='pose_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_id</th>\n",
       "      <th>pose</th>\n",
       "      <th>x_nose</th>\n",
       "      <th>y_nose</th>\n",
       "      <th>z_nose</th>\n",
       "      <th>x_left_eye_inner</th>\n",
       "      <th>y_left_eye_inner</th>\n",
       "      <th>z_left_eye_inner</th>\n",
       "      <th>x_left_eye</th>\n",
       "      <th>y_left_eye</th>\n",
       "      <th>...</th>\n",
       "      <th>z_left_heel</th>\n",
       "      <th>x_right_heel</th>\n",
       "      <th>y_right_heel</th>\n",
       "      <th>z_right_heel</th>\n",
       "      <th>x_left_foot_index</th>\n",
       "      <th>y_left_foot_index</th>\n",
       "      <th>z_left_foot_index</th>\n",
       "      <th>x_right_foot_index</th>\n",
       "      <th>y_right_foot_index</th>\n",
       "      <th>z_right_foot_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jumping_jacks_down</td>\n",
       "      <td>-5.889507</td>\n",
       "      <td>-57.637520</td>\n",
       "      <td>-45.019750</td>\n",
       "      <td>-4.656085</td>\n",
       "      <td>-62.832863</td>\n",
       "      <td>-44.571823</td>\n",
       "      <td>-3.302626</td>\n",
       "      <td>-63.386856</td>\n",
       "      <td>...</td>\n",
       "      <td>56.852562</td>\n",
       "      <td>-0.842025</td>\n",
       "      <td>35.037060</td>\n",
       "      <td>50.565020</td>\n",
       "      <td>5.842190</td>\n",
       "      <td>45.971020</td>\n",
       "      <td>50.263714</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>45.842150</td>\n",
       "      <td>41.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>jumping_jacks_down</td>\n",
       "      <td>-4.255504</td>\n",
       "      <td>-62.935925</td>\n",
       "      <td>-128.907500</td>\n",
       "      <td>-2.977403</td>\n",
       "      <td>-67.035990</td>\n",
       "      <td>-124.258545</td>\n",
       "      <td>-2.215265</td>\n",
       "      <td>-67.198250</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.129170</td>\n",
       "      <td>-1.298891</td>\n",
       "      <td>54.733307</td>\n",
       "      <td>-6.886051</td>\n",
       "      <td>3.980098</td>\n",
       "      <td>65.370830</td>\n",
       "      <td>-49.023930</td>\n",
       "      <td>-5.090634</td>\n",
       "      <td>65.641780</td>\n",
       "      <td>-42.878056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>jumping_jacks_down</td>\n",
       "      <td>-2.878917</td>\n",
       "      <td>-61.709988</td>\n",
       "      <td>-137.453340</td>\n",
       "      <td>-1.619050</td>\n",
       "      <td>-65.693750</td>\n",
       "      <td>-132.181660</td>\n",
       "      <td>-0.785822</td>\n",
       "      <td>-65.814340</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.904400</td>\n",
       "      <td>-2.119770</td>\n",
       "      <td>51.265694</td>\n",
       "      <td>-15.554097</td>\n",
       "      <td>1.994894</td>\n",
       "      <td>62.725025</td>\n",
       "      <td>-57.717957</td>\n",
       "      <td>-4.452602</td>\n",
       "      <td>62.494457</td>\n",
       "      <td>-53.804527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jumping_jacks_down</td>\n",
       "      <td>-4.242575</td>\n",
       "      <td>-60.371220</td>\n",
       "      <td>-135.094830</td>\n",
       "      <td>-3.118133</td>\n",
       "      <td>-64.416000</td>\n",
       "      <td>-129.995930</td>\n",
       "      <td>-2.369744</td>\n",
       "      <td>-64.603290</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.855729</td>\n",
       "      <td>-1.485475</td>\n",
       "      <td>59.729427</td>\n",
       "      <td>1.433403</td>\n",
       "      <td>1.950102</td>\n",
       "      <td>68.187256</td>\n",
       "      <td>-42.989098</td>\n",
       "      <td>-4.573338</td>\n",
       "      <td>68.144350</td>\n",
       "      <td>-34.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>jumping_jacks_down</td>\n",
       "      <td>-0.805543</td>\n",
       "      <td>-56.178570</td>\n",
       "      <td>-41.124413</td>\n",
       "      <td>-0.055174</td>\n",
       "      <td>-58.501305</td>\n",
       "      <td>-37.938560</td>\n",
       "      <td>0.456936</td>\n",
       "      <td>-58.473960</td>\n",
       "      <td>...</td>\n",
       "      <td>47.124107</td>\n",
       "      <td>-2.455719</td>\n",
       "      <td>52.861732</td>\n",
       "      <td>45.936783</td>\n",
       "      <td>2.699764</td>\n",
       "      <td>57.254112</td>\n",
       "      <td>27.531416</td>\n",
       "      <td>-2.288348</td>\n",
       "      <td>57.803005</td>\n",
       "      <td>26.288315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pose_id                pose    x_nose     y_nose      z_nose  \\\n",
       "0        0  jumping_jacks_down -5.889507 -57.637520  -45.019750   \n",
       "1        1  jumping_jacks_down -4.255504 -62.935925 -128.907500   \n",
       "2        2  jumping_jacks_down -2.878917 -61.709988 -137.453340   \n",
       "3        3  jumping_jacks_down -4.242575 -60.371220 -135.094830   \n",
       "4        4  jumping_jacks_down -0.805543 -56.178570  -41.124413   \n",
       "\n",
       "   x_left_eye_inner  y_left_eye_inner  z_left_eye_inner  x_left_eye  \\\n",
       "0         -4.656085        -62.832863        -44.571823   -3.302626   \n",
       "1         -2.977403        -67.035990       -124.258545   -2.215265   \n",
       "2         -1.619050        -65.693750       -132.181660   -0.785822   \n",
       "3         -3.118133        -64.416000       -129.995930   -2.369744   \n",
       "4         -0.055174        -58.501305        -37.938560    0.456936   \n",
       "\n",
       "   y_left_eye  ...  z_left_heel  x_right_heel  y_right_heel  z_right_heel  \\\n",
       "0  -63.386856  ...    56.852562     -0.842025     35.037060     50.565020   \n",
       "1  -67.198250  ...   -14.129170     -1.298891     54.733307     -6.886051   \n",
       "2  -65.814340  ...   -19.904400     -2.119770     51.265694    -15.554097   \n",
       "3  -64.603290  ...    -6.855729     -1.485475     59.729427      1.433403   \n",
       "4  -58.473960  ...    47.124107     -2.455719     52.861732     45.936783   \n",
       "\n",
       "   x_left_foot_index  y_left_foot_index  z_left_foot_index  \\\n",
       "0           5.842190          45.971020          50.263714   \n",
       "1           3.980098          65.370830         -49.023930   \n",
       "2           1.994894          62.725025         -57.717957   \n",
       "3           1.950102          68.187256         -42.989098   \n",
       "4           2.699764          57.254112          27.531416   \n",
       "\n",
       "   x_right_foot_index  y_right_foot_index  z_right_foot_index  \n",
       "0            0.092779           45.842150           41.427795  \n",
       "1           -5.090634           65.641780          -42.878056  \n",
       "2           -4.452602           62.494457          -53.804527  \n",
       "3           -4.573338           68.144350          -34.117043  \n",
       "4           -2.288348           57.803005           26.288315  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = df.drop(['pose_id', 'pose'], axis=1)\n",
    "y = df['pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(1372,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y_encoded[:100])\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18877312 -0.65045375  0.02685461  0.20443845 -0.60281692  0.09449906\n",
      "  0.21866635 -0.59462955  0.09459855  0.23366589 -0.58640269  0.09455722\n",
      "  0.16963218 -0.61561968  0.10530983  0.16282634 -0.61568161  0.10536424\n",
      "  0.15746653 -0.61564123  0.10565825  0.24806225 -0.5475492   0.27286502\n",
      "  0.14732972 -0.5861189   0.32300497  0.23942285 -0.64781766  0.06908604\n",
      "  0.17852132 -0.66757463  0.08459274  0.42556233 -0.49422367  0.19659379\n",
      " -0.04833168 -0.54912155  0.39448457  0.92858858 -0.79925015 -0.29456674\n",
      " -0.47262239 -0.56444868  0.00166814  0.73170349 -1.00751092 -0.51574488\n",
      " -0.51005622 -0.82979993 -0.47194066  0.68018517 -1.02984777 -0.5151369\n",
      " -0.50556583 -0.8969106  -0.50655354  0.65404689 -1.01691087 -0.43699762\n",
      " -0.48475145 -0.87259267 -0.45390002  0.67111878 -1.01207425 -0.49140655\n",
      " -0.48484926 -0.84896146 -0.46719902  0.75184803  0.28962721 -0.35100316\n",
      " -0.75184647 -0.28962524  0.35100316  0.00782434  0.76419951 -0.23318884\n",
      " -0.42226435  0.98918719 -0.2003364   0.0603819   0.78054889  0.13797868\n",
      "  0.1482326   0.41308764  0.42592692  0.10296953  0.67588307  0.16050714\n",
      "  0.22434488  0.29021268  0.4630921   0.01693925  0.96340935  0.10538468\n",
      "  0.19056797  0.68475132  0.4870499 ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\JR\\.conda\\envs\\solol\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.7719 - val_loss: 0.7256 - val_accuracy: 0.7545\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7074 - accuracy: 0.7423 - val_loss: 0.7267 - val_accuracy: 0.7682\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7526 - val_loss: 0.7379 - val_accuracy: 0.7773\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.7583 - val_loss: 0.7034 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.7594 - val_loss: 0.7272 - val_accuracy: 0.7636\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.7605 - val_loss: 0.7382 - val_accuracy: 0.7818\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.7514 - val_loss: 0.7466 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.7640 - val_loss: 0.7111 - val_accuracy: 0.7773\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.7366 - val_loss: 0.7352 - val_accuracy: 0.7773\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7583 - val_loss: 0.7351 - val_accuracy: 0.7773\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7640 - val_loss: 0.7038 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.7674 - val_loss: 0.7682 - val_accuracy: 0.7773\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7697 - val_loss: 0.7243 - val_accuracy: 0.7773\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7628 - val_loss: 0.7191 - val_accuracy: 0.7909\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7469 - val_loss: 0.7355 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7856 - val_loss: 0.7093 - val_accuracy: 0.7909\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7868 - val_loss: 0.7310 - val_accuracy: 0.7818\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7879 - val_loss: 0.7234 - val_accuracy: 0.7909\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.7834 - val_loss: 0.7102 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7982 - val_loss: 0.7030 - val_accuracy: 0.8091\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7970 - val_loss: 0.7155 - val_accuracy: 0.7955\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7891 - val_loss: 0.6899 - val_accuracy: 0.8091\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8062 - val_loss: 0.6864 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7628 - val_loss: 0.7066 - val_accuracy: 0.7909\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7948 - val_loss: 0.7093 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7879 - val_loss: 0.6817 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7891 - val_loss: 0.7111 - val_accuracy: 0.8091\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8050 - val_loss: 0.7143 - val_accuracy: 0.8136\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7868 - val_loss: 0.7259 - val_accuracy: 0.7909\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7959 - val_loss: 0.6930 - val_accuracy: 0.8091\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.5788 - accuracy: 0.7902 - val_loss: 0.6984 - val_accuracy: 0.8091\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.8062 - val_loss: 0.6999 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7982 - val_loss: 0.6924 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8050 - val_loss: 0.6892 - val_accuracy: 0.7818\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8027 - val_loss: 0.6801 - val_accuracy: 0.7864\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.8005 - val_loss: 0.6935 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8301 - val_loss: 0.7297 - val_accuracy: 0.7955\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.8141 - val_loss: 0.6989 - val_accuracy: 0.8091\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.8290 - val_loss: 0.6943 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.8062 - val_loss: 0.7115 - val_accuracy: 0.7909\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8267 - val_loss: 0.6896 - val_accuracy: 0.7955\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8278 - val_loss: 0.6728 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8233 - val_loss: 0.7167 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8176 - val_loss: 0.7077 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.8221 - val_loss: 0.7029 - val_accuracy: 0.7955\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.8062 - val_loss: 0.6609 - val_accuracy: 0.8091\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8210 - val_loss: 0.6730 - val_accuracy: 0.8273\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8312 - val_loss: 0.6707 - val_accuracy: 0.8227\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8255 - val_loss: 0.6735 - val_accuracy: 0.8273\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8415 - val_loss: 0.6877 - val_accuracy: 0.8273\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8130 - val_loss: 0.6720 - val_accuracy: 0.8318\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8176 - val_loss: 0.6399 - val_accuracy: 0.8409\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.8483 - val_loss: 0.6740 - val_accuracy: 0.8364\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8210 - val_loss: 0.6554 - val_accuracy: 0.8318\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8255 - val_loss: 0.6793 - val_accuracy: 0.8227\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8221 - val_loss: 0.6935 - val_accuracy: 0.8273\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8369 - val_loss: 0.7126 - val_accuracy: 0.8227\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8438 - val_loss: 0.6983 - val_accuracy: 0.8091\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8426 - val_loss: 0.6970 - val_accuracy: 0.8227\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.8449 - val_loss: 0.7284 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8233 - val_loss: 0.7337 - val_accuracy: 0.8136\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8278 - val_loss: 0.6895 - val_accuracy: 0.8318\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8438 - val_loss: 0.7430 - val_accuracy: 0.8227\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8312 - val_loss: 0.7190 - val_accuracy: 0.8091\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8506 - val_loss: 0.7038 - val_accuracy: 0.8273\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8392 - val_loss: 0.7257 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8483 - val_loss: 0.7102 - val_accuracy: 0.8091\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8290 - val_loss: 0.6794 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8438 - val_loss: 0.6833 - val_accuracy: 0.8227\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8404 - val_loss: 0.6749 - val_accuracy: 0.8091\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8495 - val_loss: 0.6883 - val_accuracy: 0.8136\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8495 - val_loss: 0.6865 - val_accuracy: 0.8318\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8415 - val_loss: 0.6729 - val_accuracy: 0.8364\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8438 - val_loss: 0.6826 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8404 - val_loss: 0.7135 - val_accuracy: 0.8364\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8267 - val_loss: 0.7145 - val_accuracy: 0.8227\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8575 - val_loss: 0.7207 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.8347 - val_loss: 0.6946 - val_accuracy: 0.8364\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8540 - val_loss: 0.7092 - val_accuracy: 0.8273\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8575 - val_loss: 0.7056 - val_accuracy: 0.8273\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8461 - val_loss: 0.7005 - val_accuracy: 0.8273\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8495 - val_loss: 0.6883 - val_accuracy: 0.8500\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8381 - val_loss: 0.6775 - val_accuracy: 0.8318\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8404 - val_loss: 0.7012 - val_accuracy: 0.8364\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8438 - val_loss: 0.6692 - val_accuracy: 0.8364\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8438 - val_loss: 0.6629 - val_accuracy: 0.8318\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8620 - val_loss: 0.7070 - val_accuracy: 0.8364\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8461 - val_loss: 0.6818 - val_accuracy: 0.8409\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8552 - val_loss: 0.7336 - val_accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8643 - val_loss: 0.7407 - val_accuracy: 0.8364\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8700 - val_loss: 0.7446 - val_accuracy: 0.8273\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8643 - val_loss: 0.7155 - val_accuracy: 0.8364\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8655 - val_loss: 0.7201 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8552 - val_loss: 0.7087 - val_accuracy: 0.8227\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8415 - val_loss: 0.7042 - val_accuracy: 0.8409\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8597 - val_loss: 0.7063 - val_accuracy: 0.8318\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8666 - val_loss: 0.7589 - val_accuracy: 0.8318\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8518 - val_loss: 0.7172 - val_accuracy: 0.8318\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8677 - val_loss: 0.6997 - val_accuracy: 0.8318\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8620 - val_loss: 0.6921 - val_accuracy: 0.8409\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.8509\n",
      "Test Loss: 0.593292772769928, Test Accuracy: 0.8509091138839722\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saves/scaler.save']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model.save('saves/exercise_recognition_model.keras')\n",
    "joblib.dump(label_encoder, 'saves/label_encoder.joblib')\n",
    "joblib.dump(scaler, 'saves/scaler.save')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
